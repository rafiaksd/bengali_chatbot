from langchain_community.document_loaders import TextLoader,PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_ollama import OllamaEmbeddings
from langchain_chroma import Chroma
from ollama import chat
import os, time, threading, winsound

def get_time_lapsed(start_time, emojis="тП░тП▒я╕П"):
    now_time = time.time()
    print(f"{emojis}   Time elapsed: {now_time-start_time:.2f} seconds\n")

#jeffh/intfloat-multilingual-e5-large-instruct:f16
#snowflake-arctic-embed2

EMBEDDING_MODEL = "snowflake-arctic-embed2"
LLM_MODEL = "gemma3:12b"
CHUNK_SIZE = 500
CHUNK_OVERLAP = 150
DB_DIR = "db_full_story"
TOP_K = 5

#load the document
loader = TextLoader("bengali_kb/full_story.txt", encoding="utf-8")
docs = loader.load()
print(f"ЁЯУХЁЯУХ Txt Loaded")
print(f"ЁЯФН Preview: {docs[0].page_content[:500]}\n--- PREVIEW END ---\n")

#split the document into chunks
splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)
chunks = splitter.split_documents(docs)

embedding_in_progress = True

def print_elapsed_time():
    start_time = time.time()
    while embedding_in_progress:
        elapsed = int(time.time() - start_time)
        if elapsed % 30 == 0 and elapsed != 0:
            print(f"тП▒я╕П {elapsed} seconds passed...")
        time.sleep(1)

timer_thread = threading.Thread(target=print_elapsed_time)
timer_thread.start()

#embed the chunks and store them in chroma db
embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL)
print(f"ЁЯУжтЬИя╕П Loaded Embedding model {EMBEDDING_MODEL}")
vector_make_start_time = time.time()

if os.path.exists(f"{DB_DIR}/chroma.sqlite3"):
    print(f"ЁЯФСЁЯУж Embedding EXISTS! Loading it...")
    vectorstore = Chroma(persist_directory=DB_DIR, embedding_function=embeddings)
else:
    print(f"ЁЯУжтЭМ Embedding NOT EXIST, creating...")
    print(f"тЬВя╕ПтЬВя╕П Chunk Size: {CHUNK_SIZE}, ЁЯквЁЯкв Overlap: {CHUNK_OVERLAP}")
    vectorstore = Chroma.from_documents(chunks, embeddings, persist_directory=DB_DIR)

embedding_in_progress = False
timer_thread.join()

print(f"ЁЯФТЁЯФТ Vector store work done...")
get_time_lapsed(vector_make_start_time)
winsound.Beep(1000, 800)

def retrieve(query:str) -> str:
    results = vectorstore.similarity_search(query, k=TOP_K)
    #print(f"ЁЯФСЁЯФР Data retrieved from database")

    #for i,result in enumerate(results):
        #print(f"ЁЯУЬ result {i+1}: {result.page_content}\n")

    return "\n\n".join([doc.page_content for doc in results])

def generate_answer(query: str, context: str) -> str:
    model = genai.GenerativeModel("gemini-pro")

    prompt = f"""ржкрзНрж░рж╕ржЩрзНржЧржЯрж┐ ржкржбрж╝рзЛ ржПржмржВ ржкрзНрж░рж╢рзНржирзЗрж░ рж╕ржВржХрзНрж╖рж┐ржкрзНржд ржУ рж╕рж░рж╛рж╕рж░рж┐ ржЙрждрзНрждрж░ ржжрж╛ржУред

ржкрзНрж░рж╕ржЩрзНржЧ:
{context}

ржкрзНрж░рж╢рзНржи:
{query}
"""

    response = model.generate_content(prompt)
    return response.text.strip()

print(f"тЬИя╕ПтЬИя╕П Using {LLM_MODEL}")

queries = [
    "ржЕржирзБржкржо ржХрж▓рзЗржЬрзЗ ржХрзА рж╕ржорзНржкржирзНржи ржХрж░рзЗржЫрзЗ?",
    "ржХрзЛржирзНржиржЧрж░ ржХрж┐",
    "ржХрж╛ржХрзЗ ржЕржирзБржкржорзЗрж░ ржнрж╛ржЧрзНржп ржжрзЗржмрждрж╛ ржмрж▓рзЗ ржЙрж▓рзНрж▓рзЗржЦ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗ?",
    "ржмрж┐ржпрж╝рзЗрж░ рж╕ржоржпрж╝ ржХрж▓рзНржпрж╛ржгрзАрж░ ржкрзНрж░ржХрзГржд ржмржпрж╝рж╕ ржХржд ржЫрж┐рж▓?",
    "ржЕржирзБржкржорзЗрж░ рж▓рж╛рж▓ржи-ржкрж╛рж▓ржи ржХрзЗ ржХрж░рзЗржЫрзЗржи?", 
    "ржЕржирзБржкржорзЗрж░ ржорж╛ ржХрзЛржи ржШрж░рзЗрж░ ржорзЗржпрж╝рзЗ?",
    "ржЕржирзБржкржо ржоржирзЗ ржХрж░рзЗ рждрж╛рж░ ржкрзВрж░рзНржг ржмржпрж╝рж╕ рж╣ржпрж╝ржирж┐ ржХрзЗржи?",
    "ржЕржирзБржкржорзЗрж░ ржнрж╛рж╖рж╛ржпрж╝ рж╕рзБржкрзБрж░рзБрж╖ ржХрж╛ржХрзЗ ржмрж▓рж╛ рж╣ржпрж╝рзЗржЫрзЗ?",
    "ржЕржирзБржкржорзЗрж░ рж▓ржЬрзНржЬрж╛рж░ ржХрж╛рж░ржг ржХрзА ржЫрж┐рж▓ ржЫрзЗрж▓рзЗржмрзЗрж▓рж╛ржпрж╝?",
    "ржЕржирзБржкржорзЗрж░ ржкрж┐рждрж╛ ржХрзА ржкрзЗрж╢рж╛ржпрж╝ ржЫрж┐рж▓рзЗржи?",
]

queries2 = [
    "When was Aelric Vortan born?",
    "What animal delivers letters in Zephyr Hollow?",
    "What is the name of Aelric's glowing pet squirrel?",
    "What did Aelric invent using mango leather and beet sugar?",
    "What happens when someone reads Whispen ink aloud?"
]

query_start_time = time.time()

for index, query in enumerate(queries):
    print(f"\n{index + 1}/{len(queries)}) {query}")
    context = retrieve(query)
    answer = generate_answer(query, context)
    print(f" - {answer}\n")
    #winsound.Beep(1000, 600)

get_time_lapsed(query_start_time, "тП░ЁЯОМЁЯУЬ")
winsound.PlaySound("success.wav", winsound.SND_FILENAME)